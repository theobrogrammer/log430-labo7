"""
Kafka Historical User Event Consumer (Event Sourcing)
SPDX-License-Identifier: LGPL-3.0-or-later
Auteurs : Gabriel C. Ullmann, Fabio Petrillo, 2025
"""

import json
from logger import Logger
from typing import Optional
from kafka import KafkaConsumer
from handlers.handler_registry import HandlerRegistry

class UserEventHistoryConsumer:
    """
    Consumer Kafka pour lire l'historique complet des Ã©vÃ©nements (Event Sourcing)
    
    Ce consumer diffÃ¨re du UserEventConsumer principal car :
    - Il utilise un group_id DISTINCT pour Ã©viter la rÃ©partition des partitions
    - Il lit depuis le DÃ‰BUT (earliest) au lieu de la fin (latest)
    - Il sauvegarde tous les Ã©vÃ©nements dans un fichier JSON pour l'audit
    """
    
    def __init__(
        self,
        bootstrap_servers: str,
        topic: str,
        group_id: str,
        registry: HandlerRegistry,
        output_file: str = "events_history.json"
    ):
        # Configuration des paramÃ¨tres Kafka pour l'Event Sourcing
        self.bootstrap_servers = bootstrap_servers
        self.topic = topic
        
        # GROUP_ID DISTINCT: Essentiel pour Ã©viter que ce consumer partage 
        # les partitions avec le consumer principal (UserEventConsumer)
        # Si mÃªme group_id -> Kafka rÃ©partit 50/50 -> on rate des messages!
        self.group_id = group_id  # Doit Ãªtre diffÃ©rent de "coolriel-group"
        
        self.registry = registry
        self.output_file = output_file  # Fichier JSON pour sauvegarder l'historique
        
        # AUTO_OFFSET_RESET = EARLIEST: 
        # - "earliest" = lit depuis le DÃ‰BUT du topic (tous les anciens messages)
        # - "latest" = lit seulement les NOUVEAUX messages (dÃ©faut du consumer principal)
        self.auto_offset_reset = "earliest"
        
        self.consumer: Optional[KafkaConsumer] = None
        self.logger = Logger.get_instance("UserEventHistoryConsumer")
        
        # Liste pour accumuler tous les Ã©vÃ©nements lus
        self.events_history = []
    
    def start(self) -> None:
        """
        DÃ©marre la lecture de l'historique complet depuis Kafka
        
        DiffÃ©rences avec le consumer principal :
        1. auto_offset_reset="earliest" -> lit TOUT l'historique
        2. group_id diffÃ©rent -> pas de conflit de partitions
        3. Sauvegarde JSON -> persistence pour audit/analyse
        """
        self.logger.info(f"ğŸ” DÃ©marrage du consumer d'historique avec group_id: {self.group_id}")
        self.logger.info(f"ğŸ“– Lecture depuis le DÃ‰BUT (earliest) du topic: {self.topic}")
        
        # CrÃ©ation du consumer Kafka configurÃ© pour l'Event Sourcing
        self.consumer = KafkaConsumer(
            self.topic,
            bootstrap_servers=self.bootstrap_servers,
            
            # GROUP_ID DISTINCT : Ã‰vite la rÃ©partition avec le consumer principal
            # Si on utilisait "coolriel-group" -> Kafka partagerait les partitions!
            group_id=self.group_id,
            
            # EARLIEST : Lit depuis le dÃ©but du topic (tous les anciens Ã©vÃ©nements)
            # Contrairement au consumer principal qui utilise "latest"
            auto_offset_reset=self.auto_offset_reset,
            
            # DÃ©sÃ©rialisation JSON : Convertit les bytes Kafka en objets Python
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            
            # Auto-commit pour marquer les messages comme lus
            enable_auto_commit=True,
            
            # Timeout pour Ã©viter d'attendre indÃ©finiment s'il n'y a plus de messages
            consumer_timeout_ms=10000  # 10 secondes max sans nouveau message
        )
        
        try:
            self.logger.info("ğŸ“š Lecture de l'historique des Ã©vÃ©nements...")
            message_count = 0
            
            # Boucle de lecture des messages historiques
            for message in self.consumer:
                event_data = message.value
                message_count += 1
                
                # Log de progression pour voir l'avancement
                if message_count % 10 == 0:
                    self.logger.info(f"ğŸ“‹ Lu {message_count} Ã©vÃ©nements...")
                
                # Traitement de chaque Ã©vÃ©nement (comme le consumer principal)
                self._process_historical_event(event_data)
                
                # Ajout Ã  l'historique pour la sauvegarde JSON
                self.events_history.append({
                    "timestamp": message.timestamp,
                    "partition": message.partition,
                    "offset": message.offset,
                    "event_data": event_data
                })
            
            self.logger.info(f"âœ… Lecture terminÃ©e! Total: {message_count} Ã©vÃ©nements traitÃ©s")
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur lors de la lecture historique: {e}", exc_info=True)
        finally:
            # SAUVEGARDE JSON : Persistence de l'historique pour audit
            self._save_history_to_json()
            self.stop()

    def _process_historical_event(self, event_data: dict) -> None:
        """
        Traite un Ã©vÃ©nement historique (similaire au consumer principal)
        
        Cette mÃ©thode peut :
        1. Appliquer les handlers pour rÃ©gÃ©nÃ©rer des emails
        2. Faire de l'analyse statistique
        3. Valider la cohÃ©rence des donnÃ©es
        """
        event_type = event_data.get('event')
        user_id = event_data.get('id')
        
        if not event_type:
            self.logger.warning(f"âš ï¸ Ã‰vÃ©nement historique sans type: {event_data}")
            return
        
        # Log dÃ©taillÃ© pour l'audit
        self.logger.debug(f"ğŸ“œ Ã‰vÃ©nement historique: {event_type} pour utilisateur {user_id}")
        
        # OPTIONNEL: Appliquer les handlers pour rÃ©gÃ©nÃ©rer les emails
        # Utile pour reconstruire l'Ã©tat aprÃ¨s une panne
        handler = self.registry.get_handler(event_type)
        if handler:
            try:
                # Note: Ceci rÃ©gÃ©nÃ©rerait les emails (peut Ãªtre dÃ©sactivÃ© selon le besoin)
                # handler.handle(event_data)
                self.logger.debug(f"âœ… Handler trouvÃ© pour {event_type}")
            except Exception as e:
                self.logger.error(f"âŒ Erreur handler historique {event_type}: {e}")
        else:
            self.logger.debug(f"â„¹ï¸ Pas de handler pour le type historique: {event_type}")
    
    def _save_history_to_json(self) -> None:
        """
        Sauvegarde l'historique complet dans un fichier JSON
        
        Le fichier contient :
        - MÃ©tadonnÃ©es Kafka (timestamp, partition, offset)
        - DonnÃ©es complÃ¨tes de chaque Ã©vÃ©nement
        - Format structurÃ© pour analyse ultÃ©rieure
        """
        if not self.events_history:
            self.logger.warning("ğŸ“‚ Aucun Ã©vÃ©nement Ã  sauvegarder")
            return
        
        try:
            # PrÃ©paration du fichier JSON avec mÃ©tadonnÃ©es
            history_data = {
                "metadata": {
                    "topic": self.topic,
                    "group_id": self.group_id,
                    "total_events": len(self.events_history),
                    "export_timestamp": json.dumps(None, default=str),  # Timestamp actuel
                    "consumer_type": "UserEventHistoryConsumer"
                },
                "events": self.events_history
            }
            
            # SAUVEGARDE JSON : Utilisation de json.dumps pour la sÃ©rialisation
            with open(self.output_file, 'w', encoding='utf-8') as f:
                # json.dumps avec indentation pour lisibilitÃ©
                json.dump(history_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"ğŸ’¾ Historique sauvegardÃ©: {self.output_file} ({len(self.events_history)} Ã©vÃ©nements)")
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur sauvegarde JSON: {e}", exc_info=True)
    
    def stop(self) -> None:
        """ArrÃªte le consumer proprement"""
        if self.consumer:
            self.consumer.close()
            self.logger.info("ğŸ›‘ Consumer d'historique arrÃªtÃ©!")